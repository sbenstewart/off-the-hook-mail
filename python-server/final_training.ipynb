{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fJf4z4towtY-",
        "outputId": "388189d5-5528-438e-ed86-b2b8f65139ca"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================================================================\n",
            "ASU CYBER360 HACKATHON - PHISHING DETECTION SYSTEM\n",
            "================================================================================\n",
            "\n",
            "âœ“ Using device: cuda\n",
            "\n",
            "[STEP 1] Loading datasets...\n",
            "âœ“ Loaded 2000 real samples\n",
            "âœ“ Generating synthetic data...\n",
            "âœ“ Generated 3000 synthetic samples\n",
            "âœ“ Total training data: 5000 samples\n",
            "âœ“ Test set: 150 samples (held out)\n",
            "\n",
            "[STEP 2] Extracting engineered features...\n",
            "âœ“ Extracted 10 features for training data\n",
            "âœ“ Extracted 10 features for test data\n",
            "\n",
            "[STEP 3] Preparing labels and validation split...\n",
            "âœ“ Training samples: 4000\n",
            "âœ“ Validation samples: 1000\n",
            "âœ“ Test samples: 150 (held out)\n",
            "\n",
            "[STEP 4] Initializing hybrid model...\n",
            "âœ“ Model: distilbert-base-uncased\n",
            "âœ“ Total parameters: 66,610,518\n",
            "âœ“ Dropout: 0.5 (reduced overfitting)\n",
            "\n",
            "[STEP 5] Creating data loaders...\n",
            "âœ“ Batch size: 16\n",
            "âœ“ Training batches: 250\n",
            "\n",
            "[STEP 6] Training model...\n",
            "\n",
            "Epoch 1/4\n",
            "------------------------------------------------------------\n",
            "Train Loss: 0.4035 | Train Accuracy: 0.8303\n",
            "Val Accuracy: 1.0000 | Precision: 1.0000 | Recall: 1.0000 | F1: 1.0000\n",
            "âœ“ Best model saved!\n",
            "\n",
            "Epoch 2/4\n",
            "------------------------------------------------------------\n",
            "Train Loss: 0.0650 | Train Accuracy: 1.0000\n",
            "Val Accuracy: 1.0000 | Precision: 1.0000 | Recall: 1.0000 | F1: 1.0000\n",
            "\n",
            "Epoch 3/4\n",
            "------------------------------------------------------------\n",
            "Train Loss: 0.0345 | Train Accuracy: 1.0000\n",
            "Val Accuracy: 1.0000 | Precision: 1.0000 | Recall: 1.0000 | F1: 1.0000\n",
            "\n",
            "Epoch 4/4\n",
            "------------------------------------------------------------\n",
            "Train Loss: 0.0256 | Train Accuracy: 1.0000\n",
            "Val Accuracy: 1.0000 | Precision: 1.0000 | Recall: 1.0000 | F1: 1.0000\n",
            "\n",
            "================================================================================\n",
            "[FINAL EVALUATION] Testing on held-out test set\n",
            "================================================================================\n",
            "\n",
            "ðŸŽ¯ FINAL TEST RESULTS:\n",
            "   Accuracy:  0.7533 (75.33%)\n",
            "   Precision: 0.6869\n",
            "   Recall:    0.9189\n",
            "   F1-Score:  0.7861\n",
            "\n",
            "ðŸ“Š Detailed Classification Report:\n",
            "                precision    recall  f1-score   support\n",
            "\n",
            "    Safe Email       0.88      0.59      0.71        76\n",
            "Phishing Email       0.69      0.92      0.79        74\n",
            "\n",
            "      accuracy                           0.75       150\n",
            "     macro avg       0.78      0.76      0.75       150\n",
            "  weighted avg       0.79      0.75      0.75       150\n",
            "\n",
            "\n",
            "================================================================================\n",
            "âœ“ Training complete! Model ready for competition submission.\n",
            "================================================================================\n"
          ]
        }
      ],
      "source": [
        "\"\"\"\n",
        "ASU Cyber360 Hackathon - Phishing Email Detector\n",
        "=================================================\n",
        "Hybrid Architecture: Fine-tuned Transformer + Engineered Features\n",
        "Target: Maximum accuracy on hidden evaluation dataset\n",
        "\"\"\"\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from transformers import (\n",
        "    AutoTokenizer,\n",
        "    AutoModel,\n",
        "    get_linear_schedule_with_warmup\n",
        ")\n",
        "from torch.optim import AdamW\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, classification_report\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Set random seeds for reproducibility\n",
        "SEED = 42\n",
        "torch.manual_seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "\n",
        "# ============================================================================\n",
        "# PART 1: ENGINEERED FEATURES EXTRACTION\n",
        "# ============================================================================\n",
        "\n",
        "class FeatureExtractor:\n",
        "    \"\"\"Extract hand-crafted features that catch phishing patterns\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        # Phishing indicators\n",
        "        self.urgency_words = ['urgent', 'immediately', 'asap', 'expire', 'expiring',\n",
        "                              'expires', 'deadline', 'hurry', 'rush', 'quick', 'now']\n",
        "        self.threat_words = ['suspend', 'suspended', 'block', 'blocked', 'deactivate',\n",
        "                            'deactivated', 'locked', 'freeze', 'frozen', 'terminate']\n",
        "        self.action_words = ['click', 'verify', 'confirm', 'update', 'validate',\n",
        "                            'authenticate', 'secure', 'restore', 'unlock']\n",
        "        self.typosquatting = ['micros0ft', 'g00gle', 'paypa1', 'amaz0n', 'app1e']\n",
        "\n",
        "    def extract_features(self, text):\n",
        "        \"\"\"Extract all 10 features from email text\"\"\"\n",
        "        text_lower = text.lower()\n",
        "\n",
        "        features = {}\n",
        "\n",
        "        # 1. Urgency count\n",
        "        features['urgency_count'] = sum(word in text_lower for word in self.urgency_words)\n",
        "\n",
        "        # 2. Threat count\n",
        "        features['threat_count'] = sum(word in text_lower for word in self.threat_words)\n",
        "\n",
        "        # 3. Action count\n",
        "        features['action_count'] = sum(word in text_lower for word in self.action_words)\n",
        "\n",
        "        # 4. URL count (various URL patterns)\n",
        "        url_pattern = r'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\\\(\\\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+'\n",
        "        features['url_count'] = len(re.findall(url_pattern, text))\n",
        "\n",
        "        # 5. Has URL (binary)\n",
        "        features['has_url'] = 1 if features['url_count'] > 0 else 0\n",
        "\n",
        "        # 6. Obfuscated URL (hxxp://, h**p://)\n",
        "        obfuscated_pattern = r'h[x*]{2}p[s]?://'\n",
        "        features['obfuscated_url'] = 1 if re.search(obfuscated_pattern, text_lower) else 0\n",
        "\n",
        "        # 7. Typosquatting\n",
        "        features['typosquatting'] = 1 if any(typo in text_lower for typo in self.typosquatting) else 0\n",
        "\n",
        "        # 8. Length\n",
        "        features['length'] = len(text)\n",
        "\n",
        "        # 9. Exclamation marks\n",
        "        features['exclamation_marks'] = text.count('!')\n",
        "\n",
        "        # 10. Capital ratio\n",
        "        capitals = sum(1 for c in text if c.isupper())\n",
        "        features['capital_ratio'] = capitals / len(text) if len(text) > 0 else 0\n",
        "\n",
        "        return features\n",
        "\n",
        "    def extract_batch(self, texts):\n",
        "        \"\"\"Extract features for a batch of texts\"\"\"\n",
        "        features_list = [self.extract_features(text) for text in texts]\n",
        "        return pd.DataFrame(features_list)\n",
        "\n",
        "\n",
        "# ============================================================================\n",
        "# PART 2: SYNTHETIC DATA GENERATION\n",
        "# ============================================================================\n",
        "\n",
        "class SyntheticDataGenerator:\n",
        "    \"\"\"Generate high-quality synthetic phishing and safe emails\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        # Phishing templates - more realistic and harder to detect\n",
        "        self.phishing_templates = [\n",
        "            \"URGENT: Your {service} account will be suspended in {time}! Click {url} to verify immediately.\",\n",
        "            \"Action Required: Unusual activity detected on your {service} account. Verify here: {url}\",\n",
        "            \"Security Alert: Your {service} password expires {time}. Update now: {url}\",\n",
        "            \"{service} Notice: Your account has been locked due to suspicious activity. Restore access: {url}\",\n",
        "            \"Final Warning: Your {service} subscription payment failed. Update payment info: {url}\",\n",
        "            \"ATTENTION: You have {number} unread messages. View them here: {url}\",\n",
        "            \"Your {service} account requires immediate verification. Click here: {url} or account will be deactivated.\",\n",
        "            \"Congratulations! You've won ${prize}. Claim your prize at: {url}\",\n",
        "            \"IT Department: System maintenance requires password reset. Update here: {url}\",\n",
        "            \"Re: Invoice #{number} - Payment confirmation needed. Download: {url}\",\n",
        "            # Harder examples that look more legitimate\n",
        "            \"Dear customer, we noticed a login from {location}. If this wasn't you, please verify: {url}\",\n",
        "            \"Your {service} security settings need review. We recommend updating them at {url}\",\n",
        "            \"Package delivery attempted. Reschedule at: {url}\",\n",
        "            \"Tax refund of ${prize} is pending. Confirm your details: {url}\",\n",
        "            \"Account verification needed for {service}. Complete within {time}: {url}\",\n",
        "            \"Hi, we're updating our privacy policy. Review and accept at {url}\",\n",
        "            \"Unusual payment activity on your account. Review transactions: {url}\",\n",
        "            \"{service} support: We detected an issue with your account. Please check {url}\",\n",
        "            \"Your document is ready. Download here: {url}\",\n",
        "            \"Action needed: Complete your {service} profile setup at {url}\"\n",
        "        ]\n",
        "\n",
        "        # Safe email templates - more varied\n",
        "        self.safe_templates = [\n",
        "            \"Hi {name}, thanks for reaching out. I'll review your proposal and get back to you by {day}.\",\n",
        "            \"Meeting scheduled for {day} at {time} in {location}. Agenda attached.\",\n",
        "            \"Project update: We've completed the {phase} phase and are moving forward with testing.\",\n",
        "            \"Welcome to {service}! We're excited to have you. Here's what you can do to get started.\",\n",
        "            \"Your order #{number} has shipped and will arrive by {day}. Track your package in your account.\",\n",
        "            \"Reminder: Your appointment with {person} is scheduled for {day} at {time}.\",\n",
        "            \"Team, great work on the presentation today. Let's regroup {day} to discuss next steps.\",\n",
        "            \"Monthly newsletter: Check out our latest features and upcoming events.\",\n",
        "            \"{name}, I reviewed the documents you sent. Everything looks good. Let's move forward.\",\n",
        "            \"Course announcement: {course} materials are now available. See you in class {day}.\",\n",
        "            # More realistic safe emails\n",
        "            \"Thanks for your payment of ${prize}. Your receipt is attached.\",\n",
        "            \"Your {service} subscription has been renewed successfully.\",\n",
        "            \"Here's the information you requested about {topic}. Let me know if you have questions.\",\n",
        "            \"Looking forward to our meeting on {day}. Please review the attached materials beforehand.\",\n",
        "            \"Your {service} account was successfully updated. No further action needed.\",\n",
        "            \"Weekly summary: {number} new messages, {number} tasks completed.\",\n",
        "            \"Reminder: Your {service} free trial ends {day}. Upgrade anytime in your account settings.\",\n",
        "            \"Hi {name}, following up on our conversation. Here are the next steps we discussed.\",\n",
        "            \"Your feedback on {topic} has been received. We appreciate your input.\",\n",
        "            \"System update completed successfully. All services are running normally.\"\n",
        "        ]\n",
        "\n",
        "        self.services = ['PayPal', 'Amazon', 'Microsoft', 'Google', 'Apple', 'Netflix',\n",
        "                        'Bank of America', 'Chase', 'Wells Fargo', 'IRS', 'Dropbox', 'LinkedIn']\n",
        "        self.times = ['24 hours', '48 hours', '3 days', 'today', 'within 1 hour', '72 hours']\n",
        "        self.urls = ['hxxp://bit.ly/a3f2x', 'https://secure-verify.net', 'http://account-check.com',\n",
        "                    'hxxps://urgent-verify.co', 'https://bit.ly/secure23', 'http://verify-account-now.com']\n",
        "        self.names = ['John', 'Sarah', 'Mike', 'Lisa', 'Tom', 'Emma', 'Alex', 'Maria']\n",
        "        self.days = ['Monday', 'Tuesday', 'next week', 'tomorrow', 'Friday', 'this week']\n",
        "        self.locations = ['New York', 'London', 'Tokyo', 'unusual location', 'unknown device']\n",
        "        self.topics = ['the project', 'your inquiry', 'the report', 'our discussion']\n",
        "\n",
        "    def generate_phishing_email(self):\n",
        "        \"\"\"Generate a single phishing email\"\"\"\n",
        "        template = np.random.choice(self.phishing_templates)\n",
        "        return template.format(\n",
        "            service=np.random.choice(self.services),\n",
        "            time=np.random.choice(self.times),\n",
        "            url=np.random.choice(self.urls),\n",
        "            number=np.random.randint(1000, 9999),\n",
        "            prize=np.random.randint(100, 10000),\n",
        "            location=np.random.choice(self.locations)\n",
        "        )\n",
        "\n",
        "    def generate_safe_email(self):\n",
        "        \"\"\"Generate a single safe email\"\"\"\n",
        "        template = np.random.choice(self.safe_templates)\n",
        "        return template.format(\n",
        "            name=np.random.choice(self.names),\n",
        "            day=np.random.choice(self.days),\n",
        "            time=f\"{np.random.randint(9, 17)}:00\",\n",
        "            location='Conference Room B',\n",
        "            phase='development',\n",
        "            service='our service',\n",
        "            number=np.random.randint(1000, 9999),\n",
        "            person='Dr. Smith',\n",
        "            course='CS 101',\n",
        "            prize=np.random.randint(10, 500),\n",
        "            topic=np.random.choice(self.topics)\n",
        "        )\n",
        "\n",
        "    def generate_dataset(self, n_samples=3000):\n",
        "        \"\"\"Generate balanced synthetic dataset\"\"\"\n",
        "        n_phishing = n_samples // 2\n",
        "        n_safe = n_samples - n_phishing\n",
        "\n",
        "        phishing_emails = [self.generate_phishing_email() for _ in range(n_phishing)]\n",
        "        safe_emails = [self.generate_safe_email() for _ in range(n_safe)]\n",
        "\n",
        "        df = pd.DataFrame({\n",
        "            'Email Text': phishing_emails + safe_emails,\n",
        "            'Email Type': ['Phishing Email'] * n_phishing + ['Safe Email'] * n_safe\n",
        "        })\n",
        "\n",
        "        return df.sample(frac=1, random_state=SEED).reset_index(drop=True)\n",
        "\n",
        "\n",
        "# ============================================================================\n",
        "# PART 3: HYBRID MODEL ARCHITECTURE\n",
        "# ============================================================================\n",
        "\n",
        "class PhishingDataset(Dataset):\n",
        "    \"\"\"Custom dataset for hybrid model\"\"\"\n",
        "\n",
        "    def __init__(self, texts, features, labels, tokenizer, max_length=256):\n",
        "        self.texts = texts\n",
        "        self.features = features\n",
        "        self.labels = labels\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_length = max_length\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.texts)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        text = str(self.texts[idx])\n",
        "\n",
        "        # Tokenize text\n",
        "        encoding = self.tokenizer(\n",
        "            text,\n",
        "            add_special_tokens=True,\n",
        "            max_length=self.max_length,\n",
        "            padding='max_length',\n",
        "            truncation=True,\n",
        "            return_tensors='pt'\n",
        "        )\n",
        "\n",
        "        return {\n",
        "            'input_ids': encoding['input_ids'].flatten(),\n",
        "            'attention_mask': encoding['attention_mask'].flatten(),\n",
        "            'features': torch.FloatTensor(self.features[idx]),\n",
        "            'label': torch.LongTensor([self.labels[idx]])\n",
        "        }\n",
        "\n",
        "\n",
        "class HybridPhishingDetector(nn.Module):\n",
        "    \"\"\"\n",
        "    Hybrid Architecture:\n",
        "    - DistilBERT for contextual understanding\n",
        "    - Engineered features for explicit pattern matching\n",
        "    - Combined through dense layers for final prediction\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, model_name='distilbert-base-uncased', n_features=10, dropout=0.5):\n",
        "        super(HybridPhishingDetector, self).__init__()\n",
        "\n",
        "        # Transformer backbone\n",
        "        self.transformer = AutoModel.from_pretrained(model_name)\n",
        "        transformer_dim = self.transformer.config.hidden_size\n",
        "\n",
        "        # Feature processing with stronger regularization\n",
        "        self.feature_bn = nn.BatchNorm1d(n_features)\n",
        "        self.feature_fc = nn.Sequential(\n",
        "            nn.Linear(n_features, 64),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.4)\n",
        "        )\n",
        "\n",
        "        # Combined classifier with increased dropout\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(transformer_dim + 64, 256),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.BatchNorm1d(256),\n",
        "            nn.Linear(256, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(128, 2)\n",
        "        )\n",
        "\n",
        "    def forward(self, input_ids, attention_mask, features):\n",
        "        # Get transformer embeddings\n",
        "        transformer_output = self.transformer(\n",
        "            input_ids=input_ids,\n",
        "            attention_mask=attention_mask\n",
        "        )\n",
        "        pooled_output = transformer_output.last_hidden_state[:, 0, :]  # [CLS] token\n",
        "\n",
        "        # Process engineered features\n",
        "        features_processed = self.feature_bn(features)\n",
        "        features_processed = torch.relu(self.feature_fc(features_processed))\n",
        "\n",
        "        # Combine and classify\n",
        "        combined = torch.cat([pooled_output, features_processed], dim=1)\n",
        "        logits = self.classifier(combined)\n",
        "\n",
        "        return logits\n",
        "\n",
        "\n",
        "# ============================================================================\n",
        "# PART 4: TRAINING PIPELINE\n",
        "# ============================================================================\n",
        "\n",
        "class PhishingDetectorTrainer:\n",
        "    \"\"\"Complete training pipeline with best practices\"\"\"\n",
        "\n",
        "    def __init__(self, model, device, learning_rate=2e-5):\n",
        "        self.model = model.to(device)\n",
        "        self.device = device\n",
        "        self.optimizer = AdamW(model.parameters(), lr=learning_rate, weight_decay=0.01)\n",
        "        self.criterion = nn.CrossEntropyLoss()\n",
        "        self.scaler = StandardScaler()\n",
        "\n",
        "    def train_epoch(self, dataloader, scheduler):\n",
        "        self.model.train()\n",
        "        total_loss = 0\n",
        "        predictions = []\n",
        "        true_labels = []\n",
        "\n",
        "        for batch in dataloader:\n",
        "            self.optimizer.zero_grad()\n",
        "\n",
        "            input_ids = batch['input_ids'].to(self.device)\n",
        "            attention_mask = batch['attention_mask'].to(self.device)\n",
        "            features = batch['features'].to(self.device)\n",
        "            labels = batch['label'].squeeze().to(self.device)\n",
        "\n",
        "            logits = self.model(input_ids, attention_mask, features)\n",
        "            loss = self.criterion(logits, labels)\n",
        "\n",
        "            loss.backward()\n",
        "            torch.nn.utils.clip_grad_norm_(self.model.parameters(), 1.0)\n",
        "            self.optimizer.step()\n",
        "            scheduler.step()\n",
        "\n",
        "            total_loss += loss.item()\n",
        "            predictions.extend(torch.argmax(logits, dim=1).cpu().numpy())\n",
        "            true_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "        avg_loss = total_loss / len(dataloader)\n",
        "        accuracy = accuracy_score(true_labels, predictions)\n",
        "\n",
        "        return avg_loss, accuracy\n",
        "\n",
        "    def evaluate(self, dataloader):\n",
        "        self.model.eval()\n",
        "        predictions = []\n",
        "        true_labels = []\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for batch in dataloader:\n",
        "                input_ids = batch['input_ids'].to(self.device)\n",
        "                attention_mask = batch['attention_mask'].to(self.device)\n",
        "                features = batch['features'].to(self.device)\n",
        "                labels = batch['label'].squeeze().to(self.device)\n",
        "\n",
        "                logits = self.model(input_ids, attention_mask, features)\n",
        "                predictions.extend(torch.argmax(logits, dim=1).cpu().numpy())\n",
        "                true_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "        accuracy = accuracy_score(true_labels, predictions)\n",
        "        precision, recall, f1, _ = precision_recall_fscore_support(\n",
        "            true_labels, predictions, average='binary'\n",
        "        )\n",
        "\n",
        "        return accuracy, precision, recall, f1, predictions, true_labels\n",
        "\n",
        "\n",
        "# ============================================================================\n",
        "# PART 5: MAIN EXECUTION\n",
        "# ============================================================================\n",
        "\n",
        "def main():\n",
        "    \"\"\"Complete pipeline: Data â†’ Features â†’ Training â†’ Evaluation\"\"\"\n",
        "\n",
        "    print(\"=\" * 80)\n",
        "    print(\"ASU CYBER360 HACKATHON - PHISHING DETECTION SYSTEM\")\n",
        "    print(\"=\" * 80)\n",
        "\n",
        "    # Device configuration\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    print(f\"\\nâœ“ Using device: {device}\")\n",
        "\n",
        "    # -------------------------------------------------------------------------\n",
        "    # STEP 1: Load and Prepare Data\n",
        "    # -------------------------------------------------------------------------\n",
        "    print(\"\\n[STEP 1] Loading datasets...\")\n",
        "\n",
        "    # Load real phishing data (2000 samples)\n",
        "    df_real = pd.read_csv('Phishing_validation_emails.csv')\n",
        "    print(f\"âœ“ Loaded {len(df_real)} real samples\")\n",
        "\n",
        "    # Generate synthetic data (3000 samples)\n",
        "    print(\"âœ“ Generating synthetic data...\")\n",
        "    generator = SyntheticDataGenerator()\n",
        "    df_synthetic = generator.generate_dataset(n_samples=3000)\n",
        "    print(f\"âœ“ Generated {len(df_synthetic)} synthetic samples\")\n",
        "\n",
        "    # Combine datasets\n",
        "    df_train_full = pd.concat([df_real, df_synthetic], ignore_index=True)\n",
        "    df_train_full = df_train_full.sample(frac=1, random_state=SEED).reset_index(drop=True)\n",
        "    print(f\"âœ“ Total training data: {len(df_train_full)} samples\")\n",
        "\n",
        "    # Load test set (NEVER use for training!)\n",
        "    df_test = pd.read_csv('se_phishing_test_set.csv')\n",
        "    df_test.columns = ['Email Text', 'Email Type']  # Standardize column names\n",
        "    print(f\"âœ“ Test set: {len(df_test)} samples (held out)\")\n",
        "\n",
        "    # -------------------------------------------------------------------------\n",
        "    # STEP 2: Extract Features\n",
        "    # -------------------------------------------------------------------------\n",
        "    print(\"\\n[STEP 2] Extracting engineered features...\")\n",
        "\n",
        "    feature_extractor = FeatureExtractor()\n",
        "\n",
        "    # Extract features for training data\n",
        "    train_features = feature_extractor.extract_batch(df_train_full['Email Text'].values)\n",
        "    print(f\"âœ“ Extracted {train_features.shape[1]} features for training data\")\n",
        "\n",
        "    # Extract features for test data\n",
        "    test_features = feature_extractor.extract_batch(df_test['Email Text'].values)\n",
        "    print(f\"âœ“ Extracted {test_features.shape[1]} features for test data\")\n",
        "\n",
        "    # -------------------------------------------------------------------------\n",
        "    # STEP 3: Prepare Labels and Split\n",
        "    # -------------------------------------------------------------------------\n",
        "    print(\"\\n[STEP 3] Preparing labels and validation split...\")\n",
        "\n",
        "    # Convert labels to binary (0 = Safe, 1 = Phishing)\n",
        "    label_map = {'Safe Email': 0, 'Phishing Email': 1, 'safe': 0, 'phishing': 1, 0: 0, 1: 1}\n",
        "\n",
        "    # Map training labels\n",
        "    df_train_full['label'] = df_train_full['Email Type'].map(label_map)\n",
        "\n",
        "    # Map test labels (handle various formats)\n",
        "    if df_test['Email Type'].dtype == 'object':\n",
        "        # String labels - normalize and map\n",
        "        df_test['Email Type'] = df_test['Email Type'].str.strip().str.lower()\n",
        "        df_test['label'] = df_test['Email Type'].replace({\n",
        "            'safe email': 0, 'phishing email': 1,\n",
        "            'safe': 0, 'phishing': 1,\n",
        "            'benign': 0, 'malicious': 1,\n",
        "            'legitimate': 0, 'spam': 1\n",
        "        })\n",
        "    else:\n",
        "        # Already numeric\n",
        "        df_test['label'] = df_test['Email Type'].astype(int)\n",
        "\n",
        "    # Verify no NaN values in labels\n",
        "    if df_train_full['label'].isna().any():\n",
        "        print(\"âš  Warning: NaN values in training labels, filling with 0\")\n",
        "        df_train_full['label'].fillna(0, inplace=True)\n",
        "\n",
        "    if df_test['label'].isna().any():\n",
        "        print(\"âš  Warning: NaN values in test labels, filling with 0\")\n",
        "        df_test['label'].fillna(0, inplace=True)\n",
        "\n",
        "    # Ensure labels are integers\n",
        "    df_train_full['label'] = df_train_full['label'].astype(int)\n",
        "    df_test['label'] = df_test['label'].astype(int)\n",
        "\n",
        "    # Split training data into train/validation (80/20)\n",
        "    train_texts, val_texts, train_feat, val_feat, train_labels, val_labels = train_test_split(\n",
        "        df_train_full['Email Text'].values,\n",
        "        train_features.values,\n",
        "        df_train_full['label'].values,\n",
        "        test_size=0.2,\n",
        "        random_state=SEED,\n",
        "        stratify=df_train_full['label']\n",
        "    )\n",
        "\n",
        "    print(f\"âœ“ Training samples: {len(train_texts)}\")\n",
        "    print(f\"âœ“ Validation samples: {len(val_texts)}\")\n",
        "    print(f\"âœ“ Test samples: {len(df_test)} (held out)\")\n",
        "\n",
        "    # Scale features\n",
        "    scaler = StandardScaler()\n",
        "    train_feat_scaled = scaler.fit_transform(train_feat)\n",
        "    val_feat_scaled = scaler.transform(val_feat)\n",
        "    test_feat_scaled = scaler.transform(test_features.values)\n",
        "\n",
        "    # -------------------------------------------------------------------------\n",
        "    # STEP 4: Initialize Model and Tokenizer\n",
        "    # -------------------------------------------------------------------------\n",
        "    print(\"\\n[STEP 4] Initializing hybrid model...\")\n",
        "\n",
        "    MODEL_NAME = 'distilbert-base-uncased'  # Fast and accurate\n",
        "    tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
        "    model = HybridPhishingDetector(model_name=MODEL_NAME, n_features=10, dropout=0.5)\n",
        "\n",
        "    print(f\"âœ“ Model: {MODEL_NAME}\")\n",
        "    print(f\"âœ“ Total parameters: {sum(p.numel() for p in model.parameters()):,}\")\n",
        "    print(f\"âœ“ Dropout: 0.5 (reduced overfitting)\")\n",
        "\n",
        "    # -------------------------------------------------------------------------\n",
        "    # STEP 5: Create DataLoaders\n",
        "    # -------------------------------------------------------------------------\n",
        "    print(\"\\n[STEP 5] Creating data loaders...\")\n",
        "\n",
        "    BATCH_SIZE = 16\n",
        "\n",
        "    train_dataset = PhishingDataset(train_texts, train_feat_scaled, train_labels, tokenizer)\n",
        "    val_dataset = PhishingDataset(val_texts, val_feat_scaled, val_labels, tokenizer)\n",
        "    test_dataset = PhishingDataset(df_test['Email Text'].values, test_feat_scaled,\n",
        "                                   df_test['label'].values, tokenizer)\n",
        "\n",
        "    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "    val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE)\n",
        "\n",
        "    print(f\"âœ“ Batch size: {BATCH_SIZE}\")\n",
        "    print(f\"âœ“ Training batches: {len(train_loader)}\")\n",
        "\n",
        "    # -------------------------------------------------------------------------\n",
        "    # STEP 6: Training\n",
        "    # -------------------------------------------------------------------------\n",
        "    print(\"\\n[STEP 6] Training model...\")\n",
        "\n",
        "    EPOCHS = 4\n",
        "    trainer = PhishingDetectorTrainer(model, device, learning_rate=2e-5)\n",
        "\n",
        "    total_steps = len(train_loader) * EPOCHS\n",
        "    scheduler = get_linear_schedule_with_warmup(\n",
        "        trainer.optimizer,\n",
        "        num_warmup_steps=total_steps // 10,\n",
        "        num_training_steps=total_steps\n",
        "    )\n",
        "\n",
        "    best_val_accuracy = 0\n",
        "\n",
        "    for epoch in range(EPOCHS):\n",
        "        print(f\"\\nEpoch {epoch + 1}/{EPOCHS}\")\n",
        "        print(\"-\" * 60)\n",
        "\n",
        "        # Train\n",
        "        train_loss, train_acc = trainer.train_epoch(train_loader, scheduler)\n",
        "        print(f\"Train Loss: {train_loss:.4f} | Train Accuracy: {train_acc:.4f}\")\n",
        "\n",
        "        # Validate\n",
        "        val_acc, val_prec, val_rec, val_f1, _, _ = trainer.evaluate(val_loader)\n",
        "        print(f\"Val Accuracy: {val_acc:.4f} | Precision: {val_prec:.4f} | Recall: {val_rec:.4f} | F1: {val_f1:.4f}\")\n",
        "\n",
        "        # Save best model\n",
        "        if val_acc > best_val_accuracy:\n",
        "            best_val_accuracy = val_acc\n",
        "            torch.save(model.state_dict(), 'best_phishing_detector.pth')\n",
        "            print(\"âœ“ Best model saved!\")\n",
        "\n",
        "    # -------------------------------------------------------------------------\n",
        "    # STEP 7: Final Evaluation on Test Set\n",
        "    # -------------------------------------------------------------------------\n",
        "    print(\"\\n\" + \"=\" * 80)\n",
        "    print(\"[FINAL EVALUATION] Testing on held-out test set\")\n",
        "    print(\"=\" * 80)\n",
        "\n",
        "    # Load best model\n",
        "    model.load_state_dict(torch.load('best_phishing_detector.pth'))\n",
        "\n",
        "    test_acc, test_prec, test_rec, test_f1, test_preds, test_true = trainer.evaluate(test_loader)\n",
        "\n",
        "    print(f\"\\nðŸŽ¯ FINAL TEST RESULTS:\")\n",
        "    print(f\"   Accuracy:  {test_acc:.4f} ({test_acc*100:.2f}%)\")\n",
        "    print(f\"   Precision: {test_prec:.4f}\")\n",
        "    print(f\"   Recall:    {test_rec:.4f}\")\n",
        "    print(f\"   F1-Score:  {test_f1:.4f}\")\n",
        "\n",
        "    print(\"\\nðŸ“Š Detailed Classification Report:\")\n",
        "    print(classification_report(test_true, test_preds,\n",
        "                               target_names=['Safe Email', 'Phishing Email']))\n",
        "\n",
        "    print(\"\\n\" + \"=\" * 80)\n",
        "    print(\"âœ“ Training complete! Model ready for competition submission.\")\n",
        "    print(\"=\" * 80)\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NAXcSxpC6Xy1"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}